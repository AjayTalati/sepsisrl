{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This notebook reads in the discretised input data and then preprocesses the model features\n",
    "# Firstly, values deemed excessively high/low are capped\n",
    "# Relevant binary features and normally/log-normally features are standardised accordingly\n",
    "# Training and test sets are split - 70% train, 10% validation, 20% test\n",
    "# Resulting datasets are saved to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "disc_inp_data = pd.read_csv(\"../data/discretised_input_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0      224552\n",
      " 100     15583\n",
      "-100      2315\n",
      "Name: reward, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# add rewards - sparsely for now; reward function shaping comes in a separate script\n",
    "disc_inp_data['reward'] = 0\n",
    "for i in disc_inp_data.index:\n",
    "    if i == 0:\n",
    "        continue\n",
    "    else:\n",
    "        if disc_inp_data.ix[i, 'icustayid'] != disc_inp_data.ix[i-1, 'icustayid']:\n",
    "            if disc_inp_data.ix[i-1, 'died_in_hosp'] == 1:\n",
    "                disc_inp_data.ix[i-1,'reward'] = -100\n",
    "            elif disc_inp_data.ix[i-1, 'died_in_hosp'] == 0:\n",
    "                disc_inp_data.ix[i-1,'reward'] = 100\n",
    "            else:\n",
    "                print \"error in row\", i-1\n",
    "if disc_inp_data.ix[len(disc_inp_data)-1, 'died_in_hosp'] == 1:\n",
    "    disc_inp_data.ix[len(disc_inp_data)-1, 'reward'] = -100\n",
    "elif disc_inp_data.ix[len(disc_inp_data)-1, 'died_in_hosp'] == 0:\n",
    "     disc_inp_data.ix[len(disc_inp_data)-1, 'reward'] = 100\n",
    "print disc_inp_data['reward'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# now split into train/validation/test sets\n",
    "import random\n",
    "unique_ids = disc_inp_data['icustayid'].unique()\n",
    "random.shuffle(unique_ids)\n",
    "train_sample = 0.7\n",
    "val_sample = 0.1\n",
    "test_sample = 0.2\n",
    "train_num = int(len(unique_ids) * 0.7)\n",
    "val_num = int(len(unique_ids)*0.1) + train_num\n",
    "train_ids = unique_ids[:train_num]\n",
    "val_ids = unique_ids[train_num:val_num]\n",
    "test_ids = unique_ids[val_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_set = DataFrame()\n",
    "train_set = disc_inp_data.loc[disc_inp_data['icustayid'].isin(train_ids)]\n",
    "\n",
    "val_set = DataFrame()\n",
    "val_set = disc_inp_data.loc[disc_inp_data['icustayid'].isin(val_ids)]\n",
    "\n",
    "test_set = DataFrame()\n",
    "test_set = disc_inp_data.loc[disc_inp_data['icustayid'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/generic.py:4702: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# cap values in train and test\n",
    "caps = pd.read_csv(\"capping_values.csv\")\n",
    "for i in caps.index:\n",
    "    param = caps.ix[i,'parameter'][1:-1]\n",
    "    maxval = caps.ix[i,'limsup']\n",
    "    minval = caps.ix[i,'liminf']\n",
    "    train_set[param][train_set[param] >= maxval] = maxval\n",
    "    train_set[param][train_set[param] <= minval] = minval\n",
    "    val_set[param][val_set[param] >= maxval] = maxval\n",
    "    val_set[param][val_set[param] <= minval] = minval\n",
    "    test_set[param][test_set[param] >= maxval] = maxval\n",
    "    test_set[param][test_set[param] <= minval] = minval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "binary_fields = ['gender','mechvent','re_admission']\n",
    "norm_fields= ['age','Weight_kg','GCS','HR','SysBP','MeanBP','DiaBP','RR','Temp_C','FiO2_1',\n",
    "    'Potassium','Sodium','Chloride','Glucose','Magnesium','Calcium',\n",
    "    'Hb','WBC_count','Platelets_count','PTT','PT','Arterial_pH','paO2','paCO2',\n",
    "    'Arterial_BE','HCO3','Arterial_lactate','SOFA','SIRS','Shock_Index',\n",
    "    'PaO2_FiO2','cumulated_balance_tev', 'elixhauser', 'Albumin', u'CO2_mEqL', 'Ionised_Ca']\n",
    "log_fields = ['max_dose_vaso','SpO2','BUN','Creatinine','SGOT','SGPT','Total_bili','INR',\n",
    "              'input_total_tev','input_4hourly_tev','output_total','output_4hourly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/frame.py:2440: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "# normalise binary fields\n",
    "train_set[binary_fields] = train_set[binary_fields] - 0.5 \n",
    "val_set[binary_fields] = val_set[binary_fields] - 0.5 \n",
    "test_set[binary_fields] = test_set[binary_fields] - 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# normal distn fields\n",
    "for item in norm_fields:\n",
    "    av = train_set[item].mean()\n",
    "    std = train_set[item].std()\n",
    "    train_set[item] = (train_set[item] - av) / std\n",
    "    val_set[item] = (val_set[item] - av) / std\n",
    "    test_set[item] = (test_set[item] - av) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# log normal fields\n",
    "train_set[log_fields] = np.log(0.1 + train_set[log_fields])\n",
    "val_set[log_fields] = np.log(0.1 + val_set[log_fields])\n",
    "test_set[log_fields] = np.log(0.1 + test_set[log_fields])\n",
    "for item in log_fields:\n",
    "    av = train_set[item].mean()\n",
    "    std = train_set[item].std()\n",
    "    train_set[item] = (train_set[item] - av) / std\n",
    "    val_set[item] = (val_set[item] - av) / std\n",
    "    test_set[item] = (test_set[item] - av) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>elixhauser</th>\n",
       "      <th>re_admission</th>\n",
       "      <th>died_in_hosp</th>\n",
       "      <th>mortality_90d</th>\n",
       "      <th>...</th>\n",
       "      <th>median_dose_vaso</th>\n",
       "      <th>max_dose_vaso</th>\n",
       "      <th>input_total_tev</th>\n",
       "      <th>input_4hourly_tev</th>\n",
       "      <th>output_total</th>\n",
       "      <th>output_4hourly</th>\n",
       "      <th>cumulated_balance_tev</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7245052800</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.972456</td>\n",
       "      <td>-1.807766</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.379552</td>\n",
       "      <td>0.133952</td>\n",
       "      <td>1.254772</td>\n",
       "      <td>-0.380319</td>\n",
       "      <td>0.423948</td>\n",
       "      <td>0.090690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7245067200</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.972456</td>\n",
       "      <td>-1.807766</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.379552</td>\n",
       "      <td>0.319865</td>\n",
       "      <td>1.240192</td>\n",
       "      <td>-0.040929</td>\n",
       "      <td>0.646407</td>\n",
       "      <td>0.317665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7245081600</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.972456</td>\n",
       "      <td>-1.807766</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.379552</td>\n",
       "      <td>0.327648</td>\n",
       "      <td>0.368842</td>\n",
       "      <td>0.324865</td>\n",
       "      <td>1.034249</td>\n",
       "      <td>0.095431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7245096000</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.972456</td>\n",
       "      <td>-1.807766</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.379552</td>\n",
       "      <td>0.332030</td>\n",
       "      <td>0.203508</td>\n",
       "      <td>0.397886</td>\n",
       "      <td>0.735431</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7245110400</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.972456</td>\n",
       "      <td>-1.807766</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.379552</td>\n",
       "      <td>0.336366</td>\n",
       "      <td>0.203508</td>\n",
       "      <td>0.439922</td>\n",
       "      <td>0.620478</td>\n",
       "      <td>-0.042354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  bloc  icustayid   charttime  gender       age  elixhauser  \\\n",
       "0           0     1          3  7245052800    -0.5 -0.972456   -1.807766   \n",
       "1           1     2          3  7245067200    -0.5 -0.972456   -1.807766   \n",
       "2           2     3          3  7245081600    -0.5 -0.972456   -1.807766   \n",
       "3           3     4          3  7245096000    -0.5 -0.972456   -1.807766   \n",
       "4           4     5          3  7245110400    -0.5 -0.972456   -1.807766   \n",
       "\n",
       "   re_admission  died_in_hosp  mortality_90d   ...    median_dose_vaso  \\\n",
       "0          -0.5             0              1   ...                 0.0   \n",
       "1          -0.5             0              1   ...                 0.0   \n",
       "2          -0.5             0              1   ...                 0.0   \n",
       "3          -0.5             0              1   ...                 0.0   \n",
       "4          -0.5             0              1   ...                 0.0   \n",
       "\n",
       "   max_dose_vaso  input_total_tev  input_4hourly_tev  output_total  \\\n",
       "0      -0.379552         0.133952           1.254772     -0.380319   \n",
       "1      -0.379552         0.319865           1.240192     -0.040929   \n",
       "2      -0.379552         0.327648           0.368842      0.324865   \n",
       "3      -0.379552         0.332030           0.203508      0.397886   \n",
       "4      -0.379552         0.336366           0.203508      0.439922   \n",
       "\n",
       "   output_4hourly  cumulated_balance_tev  vaso_input  iv_input  reward  \n",
       "0        0.423948               0.090690         0.0       4.0       0  \n",
       "1        0.646407               0.317665         0.0       4.0       0  \n",
       "2        1.034249               0.095431         0.0       2.0       0  \n",
       "3        0.735431               0.012464         0.0       2.0       0  \n",
       "4        0.620478              -0.042354         0.0       2.0       0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_set.to_csv('../data/rl_train_set_unscaled.csv',index = False)\n",
    "val_set.to_csv('./data/rl_val_set_unscaled.csv', index = False)\n",
    "test_set.to_csv('./data/rl_test_set_unscaled.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# scale features to [0,1] in train set, similar in val and test\n",
    "import copy\n",
    "scalable_fields = copy.deepcopy(binary_fields)\n",
    "scalable_fields.extend(norm_fields)\n",
    "scalable_fields.extend(log_fields)\n",
    "scalable_fields.extend(missed_fields)\n",
    "for col in scalable_fields:\n",
    "    minimum = min(train_set[col])\n",
    "    maximum = max(train_set[col])\n",
    "    train_set[col] = (train_set[col] - minimum)/(maximum-minimum)\n",
    "    val_set[col] = (val_set[col] - minimum)/(maximum-minimum)\n",
    "    test_set[col] = (test_set[col] - minimum)/(maximum-minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set.to_csv('../data/rl_train_set_scaled.csv',index = False)\n",
    "val_set.to_csv('../data/rl_val_set_scaled.csv', index = False)\n",
    "test_set.to_csv('../data/rl_test_set_scaled.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
