{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learn the physician policy - ie, pi(a|s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/rl_train_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('../data/rl_val_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/rl_test_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features (state vector) and labels (action taken) out of the dataframe for train \n",
    "# and val sets\n",
    "def preproc(df_in, iv_bins = 5):\n",
    "    df = df_in.copy()\n",
    "    actions_raw = df[['iv_input', 'vaso_input']].values\n",
    "    keep_arr = np.loadtxt('../data/state_features.txt', dtype=str)\n",
    "    df = df[keep_arr]\n",
    "    actions_proc = (iv_bins*actions_raw[:, 0] + actions_raw[:, 1]).astype(int)\n",
    "    hist = np.histogram(actions_proc, 25)\n",
    "    actions_proc = pd.get_dummies(actions_proc).values\n",
    "    #print(hist) just to check\n",
    "    return df.values, actions_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_sample(batch_size, features, labels):\n",
    "    idx = np.random.choice(np.arange(len(features)), batch_size)\n",
    "    return (np.vstack(features[idx]), np.vstack(labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feat, train_labels = preproc(train_data)\n",
    "val_feat, val_labels = preproc(val_data)\n",
    "test_feat, test_labels = preproc(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_length = len(train_feat[0])\n",
    "batch_size = 100\n",
    "num_actions = 25\n",
    "num_steps = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# todo - reduce network size\n",
    "class PolicyModel():\n",
    "    def __init__(self):\n",
    "        self.input_feat = tf.placeholder(tf.float32, shape = [None, feature_length])\n",
    "        self.labels = tf.placeholder(tf.float32, shape = [None, num_actions])\n",
    "        self.phase = tf.placeholder(tf.bool)\n",
    "        \n",
    "        self.fc_1 = tf.contrib.layers.fully_connected(self.input_feat, 1000, activation_fn=tf.nn.relu)\n",
    "        self.bn_1 = tf.contrib.layers.batch_norm(self.fc_1, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_2 = tf.contrib.layers.fully_connected(self.bn_1 , 500, activation_fn=tf.nn.relu)    \n",
    "        self.bn_2 = tf.contrib.layers.batch_norm(self.fc_2, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_3 = tf.contrib.layers.fully_connected(self.bn_2 , 300, activation_fn=tf.nn.relu)\n",
    "        self.bn_3 = tf.contrib.layers.batch_norm(self.fc_3, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_4 = tf.contrib.layers.fully_connected(self.bn_3 , 150, activation_fn=tf.nn.relu)\n",
    "        self.bn_4 = tf.contrib.layers.batch_norm(self.fc_4, center=True, scale=True, is_training=self.phase)\n",
    "        \n",
    "        self.logits = tf.contrib.layers.fully_connected(self.bn_4 , num_actions, activation_fn=None)\n",
    "        self.output = tf.nn.softmax(self.logits)\n",
    "        self.reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        self.reg_constant = 0.01 \n",
    "        \n",
    "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(self.labels, 1), tf.argmax(self.output, 1)),'float32'))\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.logits, labels = self.labels)) + self.reg_constant*sum(self.reg_losses)\n",
    "\n",
    "        \n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_ops):\n",
    "            self.train_step = tf.train.AdamOptimizer().minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prints out accuracy on the relevant dataset and returns the policy. \n",
    "# This is the probability of taking each action in the action space from that state\n",
    "\n",
    "def get_policy(dataset):\n",
    "    if dataset == 'train':\n",
    "        features, labels = train_feat,train_labels\n",
    "    elif dataset == 'val':\n",
    "        features, labels = val_feat,val_labels\n",
    "    elif dataset == 'test':\n",
    "        features, labels = test_feat,test_labels\n",
    "    \n",
    "    op = np.zeros((len(features), num_actions))\n",
    "    total_acc = 0\n",
    "    j = 0\n",
    "    while (j < len(features)):\n",
    "        feat = None\n",
    "        labels = None\n",
    "        if len(features) - j < batch_size:\n",
    "            feat = features[j:-1]\n",
    "            lbls = features[j:-1]\n",
    "        else:\n",
    "            feat = features[j:j+batch_size]\n",
    "            lbls = labels[j:j+batch_size]\n",
    "        feat = feat.reshape(len(feat), feature_length)\n",
    "        lbls = lbls.reshape(len(lbls), num_actions)\n",
    "        if j%10000 == 0: print('Processing val set indx: ', j )\n",
    "        softmax, accuracy = sess.run([mdl.output, mdl.accuracy], feed_dict={mdl.input_feat : feat, mdl.phase: 0, mdl.labels: lbls, mdl.phase: 0})\n",
    "        total_acc += accuracy\n",
    "        op[j:j+len(feat)] = softmax\n",
    "        if len(features) - j < batch_size:\n",
    "            j = len(features)\n",
    "        else: j+=batch_size\n",
    "        final_acc = total_acc/(len(op)/batch_size)\n",
    "    return op, final_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    tf.reset_default_graph()\n",
    "    mdl = PolicyModel()\n",
    "    config = tf.ConfigProto()\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init)\n",
    "        net_loss = 0\n",
    "        net_accuracy = 0.0\n",
    "        print('Starting training!')\n",
    "        for i in range(num_steps):\n",
    "            feat, labels = batch_sample(batch_size, train_feat, train_labels)\n",
    "            \n",
    "            _, loss, accuracy = sess.run([mdl.train_step, mdl.loss, mdl.accuracy], feed_dict={mdl.input_feat : feat, mdl.labels: labels, mdl.phase: 1})\n",
    "            \n",
    "            net_loss += loss\n",
    "            net_accuracy += accuracy\n",
    "            if i % 1000 == 0 and i > 0:\n",
    "                av_loss = net_loss/1000.0\n",
    "                av_accuracy = net_accuracy/1000.0\n",
    "                print(\"Step: \", i, \"Average loss is: \", av_loss, \"Average accuracy is: \", av_accuracy)\n",
    "                net_loss = 0.0\n",
    "                net_accuracy = 0.0\n",
    "                \n",
    "        # Commented out for now\n",
    "        # train_policy, train_acc = get_policy('train')\n",
    "        val_policy, val_acc = get_policy('val')\n",
    "        test_policy, test_acc = get_policy('test')\n",
    "    print('Val and test set accuracies: ', val_acc, test_acc)\n",
    "    return val_policy, test_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training!\n",
      "('Step: ', 1000, 'Average loss is: ', 1.9168550771474839, 'Average accuracy is: ', 0.33235000203549864)\n",
      "('Step: ', 2000, 'Average loss is: ', 1.6933085815906526, 'Average accuracy is: ', 0.36175000050663947)\n",
      "('Step: ', 3000, 'Average loss is: ', 1.6561540344953536, 'Average accuracy is: ', 0.37072999975085258)\n",
      "('Step: ', 4000, 'Average loss is: ', 1.6228221287727356, 'Average accuracy is: ', 0.38398999892175195)\n",
      "('Step: ', 5000, 'Average loss is: ', 1.595211664557457, 'Average accuracy is: ', 0.39240999887883665)\n",
      "('Step: ', 6000, 'Average loss is: ', 1.5659543656110764, 'Average accuracy is: ', 0.4044099981188774)\n",
      "('Step: ', 7000, 'Average loss is: ', 1.537966688990593, 'Average accuracy is: ', 0.41733999821543694)\n",
      "('Step: ', 8000, 'Average loss is: ', 1.5096219664812087, 'Average accuracy is: ', 0.42986999785900115)\n",
      "('Step: ', 9000, 'Average loss is: ', 1.4769313097000123, 'Average accuracy is: ', 0.44551999789476393)\n",
      "('Step: ', 10000, 'Average loss is: ', 1.4544493557214737, 'Average accuracy is: ', 0.45412999752163885)\n",
      "('Step: ', 11000, 'Average loss is: ', 1.4263875242471695, 'Average accuracy is: ', 0.466299997061491)\n",
      "('Step: ', 12000, 'Average loss is: ', 1.3980241150856019, 'Average accuracy is: ', 0.47819999676942826)\n",
      "('Step: ', 13000, 'Average loss is: ', 1.3787385993003844, 'Average accuracy is: ', 0.48605999669432642)\n",
      "('Step: ', 14000, 'Average loss is: ', 1.3479620872735978, 'Average accuracy is: ', 0.50060999649763105)\n",
      "('Step: ', 15000, 'Average loss is: ', 1.335850127696991, 'Average accuracy is: ', 0.50271999585628513)\n",
      "('Step: ', 16000, 'Average loss is: ', 1.30747630494833, 'Average accuracy is: ', 0.51649999633431432)\n",
      "('Step: ', 17000, 'Average loss is: ', 1.2884208137989044, 'Average accuracy is: ', 0.52498999702930449)\n",
      "('Step: ', 18000, 'Average loss is: ', 1.2761704534292222, 'Average accuracy is: ', 0.5295899969935417)\n",
      "('Step: ', 19000, 'Average loss is: ', 1.2597232170104979, 'Average accuracy is: ', 0.53570999649167061)\n",
      "('Step: ', 20000, 'Average loss is: ', 1.2396643040776252, 'Average accuracy is: ', 0.54477999702095981)\n",
      "('Step: ', 21000, 'Average loss is: ', 1.2249002239108087, 'Average accuracy is: ', 0.5504699959754944)\n",
      "('Step: ', 22000, 'Average loss is: ', 1.207768795132637, 'Average accuracy is: ', 0.5563199965655804)\n",
      "('Step: ', 23000, 'Average loss is: ', 1.1925932728648185, 'Average accuracy is: ', 0.56142999818921091)\n",
      "('Step: ', 24000, 'Average loss is: ', 1.1810853074789047, 'Average accuracy is: ', 0.56587999877333639)\n",
      "('Step: ', 25000, 'Average loss is: ', 1.1702085781693459, 'Average accuracy is: ', 0.56954999759793279)\n",
      "('Step: ', 26000, 'Average loss is: ', 1.1558880719542504, 'Average accuracy is: ', 0.57600999972224232)\n",
      "('Step: ', 27000, 'Average loss is: ', 1.1476650846004486, 'Average accuracy is: ', 0.58071999830007548)\n",
      "('Step: ', 28000, 'Average loss is: ', 1.1377692336440086, 'Average accuracy is: ', 0.58350999858975405)\n",
      "('Step: ', 29000, 'Average loss is: ', 1.1290131629705429, 'Average accuracy is: ', 0.58784999850392339)\n",
      "('Step: ', 30000, 'Average loss is: ', 1.1123062024116517, 'Average accuracy is: ', 0.59160999825596805)\n",
      "('Step: ', 31000, 'Average loss is: ', 1.1055274599790572, 'Average accuracy is: ', 0.5969099983274937)\n",
      "('Step: ', 32000, 'Average loss is: ', 1.0954575664401054, 'Average accuracy is: ', 0.59789999908208846)\n",
      "('Step: ', 33000, 'Average loss is: ', 1.0833284898400306, 'Average accuracy is: ', 0.6040399984121323)\n",
      "('Step: ', 34000, 'Average loss is: ', 1.0795972114205361, 'Average accuracy is: ', 0.60802999934554103)\n",
      "('Step: ', 35000, 'Average loss is: ', 1.0745988346338271, 'Average accuracy is: ', 0.60862999925017358)\n",
      "('Step: ', 36000, 'Average loss is: ', 1.0661436088085174, 'Average accuracy is: ', 0.61048999893665312)\n",
      "('Step: ', 37000, 'Average loss is: ', 1.0553043202161789, 'Average accuracy is: ', 0.61625999918580054)\n",
      "('Step: ', 38000, 'Average loss is: ', 1.0489479082822799, 'Average accuracy is: ', 0.61732000014185906)\n",
      "('Step: ', 39000, 'Average loss is: ', 1.040060574054718, 'Average accuracy is: ', 0.62042999923229214)\n",
      "('Step: ', 40000, 'Average loss is: ', 1.0343538318276406, 'Average accuracy is: ', 0.62038999962806707)\n",
      "('Step: ', 41000, 'Average loss is: ', 1.0290921016335488, 'Average accuracy is: ', 0.62354999989271165)\n",
      "('Step: ', 42000, 'Average loss is: ', 1.0222765880823135, 'Average accuracy is: ', 0.62580000013113024)\n",
      "('Step: ', 43000, 'Average loss is: ', 1.015072950899601, 'Average accuracy is: ', 0.62846999996900554)\n",
      "('Step: ', 44000, 'Average loss is: ', 1.0045011241436004, 'Average accuracy is: ', 0.6311700004339218)\n",
      "('Step: ', 45000, 'Average loss is: ', 1.0035821164846421, 'Average accuracy is: ', 0.63339000016450886)\n",
      "('Step: ', 46000, 'Average loss is: ', 0.99624025940895078, 'Average accuracy is: ', 0.63471000054478643)\n",
      "('Step: ', 47000, 'Average loss is: ', 0.99063591098785397, 'Average accuracy is: ', 0.63802000033855433)\n",
      "('Step: ', 48000, 'Average loss is: ', 0.98543142104148862, 'Average accuracy is: ', 0.63963000041246409)\n",
      "('Step: ', 49000, 'Average loss is: ', 0.98363749247789378, 'Average accuracy is: ', 0.64136000090837475)\n",
      "('Step: ', 50000, 'Average loss is: ', 0.98109067302942277, 'Average accuracy is: ', 0.64128000003099439)\n",
      "('Processing test set indx: ', 0)\n",
      "('Processing test set indx: ', 10000)\n",
      "('Processing test set indx: ', 20000)\n",
      "('Processing test set indx: ', 30000)\n",
      "('Processing test set indx: ', 40000)\n",
      "('Final accuracy on test: ', 0.30520479915017218)\n"
     ]
    }
   ],
   "source": [
    "val_policy, test_policy = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  save the learned policy as a numpy array with the columns as icustayid, bloc, iv input, vaso input,\n",
    "#  action index (of 25), and probability distribution over actions ( this is 25 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_data = val_data[['icustayid', 'bloc', 'iv_input', 'vaso_input']].values\n",
    "val_actions = (5*val_data['iv_input'].values + val_data['vaso_input']).values.astype(int)\n",
    "val_pickle = np.concatenate((v_data, val_actions.reshape(len(val_actions), 1), val_policy), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_data = test_data[['icustayid', 'bloc', 'iv_input', 'vaso_input']].values\n",
    "test_actions = (5*test_data['iv_input'].values + test_data['vaso_input']).values.astype(int)\n",
    "test_pickle = np.concatenate((t_data, test_actions.reshape(len(test_actions), 1), test_policy), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"val_policy.p\", \"wb\") as f:\n",
    "    pickle.dump(val_pickle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"test_policy.p\", \"wb\") as f:\n",
    "    pickle.dump(test_pickle, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
