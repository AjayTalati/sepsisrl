{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Implements the Doubly robust value estimator for the learned policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>state</th>\n",
       "      <th>reward</th>\n",
       "      <th>max_dose_vaso</th>\n",
       "      <th>iv_tev_in</th>\n",
       "      <th>mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  bloc  icustayid  state  reward  max_dose_vaso  iv_tev_in  \\\n",
       "0           0     1          3   1128       0            0.0        4.0   \n",
       "1           1     2          3   1128       0            0.0        4.0   \n",
       "2           2     3          3   1172       0            0.0        2.0   \n",
       "3           3     4          3   1172       0            0.0        2.0   \n",
       "4           4     5          3    464       0            0.0        2.0   \n",
       "\n",
       "   mortality  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/rl_train_data_final_disc.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('../data/rl_val_data_final_disc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/rl_test_data_final_disc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in the policies for the physician on val and test sets\n",
    "phys_policy_val = pickle.load(open(\"val_policy\", \"rb\" ))\n",
    "phys_policy_test = pickle.load(open(\"test_policy\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the indices for indexing into the policy matrix. \n",
    "indices = phys_policy_test[:,4].astype(int) + 5\n",
    "phys_action_probs = phys_policy_test[range(len(phys_policy_test)),indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Two cells below - load the actions and q values associated with the agent policy - these are outputted by the\n",
    "# neural network used to learn the optimal policy and eval_policy respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "agent_actions = pickle.load(open('../continuous/dqn_normal/dqn_normal_actions_test.p', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "agent_q = pickle.load(open('./eval_policy/policy_q_test', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# add the actions and q values associated with agent performance on the test set to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test['agent_action'] = np.array(agent_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test['agent_q'] = np.array(agent_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['phys_prob'] = phys_action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv,vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_ids = df_test['icustayid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = [] # contains the value estimates for each trajectory\n",
    "# This discount factor (gamma) should be the same as that used to find Q(s,a) for the physician policy (sarsa_physician)\n",
    "# and in eval_policy\n",
    "gamma = 1\n",
    "for uid in unique_ids:\n",
    "    trajectory = df_test.loc[df_test['icustayid'] == uid]\n",
    "    cur_val = 0\n",
    "    reversed_traj = trajectory.iloc[::-1]\n",
    "    t = len(reversed_traj)\n",
    "    for row in reversed_traj.index:\n",
    "        state = df_test.ix[row,'state']\n",
    "        \n",
    "        iv = df_test.ix[row,'iv_tev_in']\n",
    "        vaso = df_test.ix[row, 'max_dose_vaso']\n",
    "        phys_action = action_map[(iv,vaso)]\n",
    "        phys_prob = df_test.ix[row,'phys_prob']\n",
    "\n",
    "        agent_action = reversed_traj.ix[row,'agent_action']\n",
    "\n",
    "        agent_val = reversed_traj.ix[row, 'agent_q']\n",
    "        \n",
    "        reward = reversed_traj.ix[row, 'reward']\n",
    "\n",
    "        # calculate rho - the importance sampling factor         \n",
    "        if agent_action == phys_action:\n",
    "            rho = 1.0/phys_prob\n",
    "        else:\n",
    "            rho = 0\n",
    "        \n",
    "#         # Debug related things below\n",
    "#         print \"row \", row\n",
    "#         print \"phys_prob \", phys_prob\n",
    "#         print \"state\", state\n",
    "#         print \"actions \", agent_action, phys_action\n",
    "#         print \"agent val \", agent_val\n",
    "#         print \"cur val before update  \", cur_val\n",
    "        \n",
    "        \n",
    "        cur_val = agent_val + rho*(reward + gamma*cur_val - agent_val)\n",
    "        t -= 1\n",
    "    \n",
    "#         More debugging below\n",
    "#         print \"cur val after update  \", cur_val\n",
    "#         print \"rho \", rho\n",
    "#         print \"reward \", reward\n",
    "\n",
    "    assert (t == 0)\n",
    "\n",
    "#     TODO: sort out the problem when some of the vals are way too high - maybe exclude these\n",
    "#     trajectories from the evaluation?\n",
    "\n",
    "#     if abs(cur_val) > 1000:\n",
    "#         print uid\n",
    "#         bad_uids.append(uid)\n",
    "\n",
    "    values.append(cur_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3580"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "values = pd.Series(values)\n",
    "\n",
    "# TODO - this is a hack to get rid of trajectories that resulted\n",
    "# in extremely high values, as a result of rho being very large. \n",
    "# Think of a better way of doing this - perhaps by restricting\n",
    "# the actions that the agent can take at any timestep?\n",
    "values = (values[(values >= -15) & (values <= 15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3443"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.7414900121408685"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.170391061452515"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #  The code here evaluates the expected return under the physician policy\n",
    "# Note that this assumes a discount factor of 1 - need to adjust this to work for \n",
    "# other discount factors too\n",
    "phys_vals = []\n",
    "for uid in unique_ids:\n",
    "    traj = df_test.loc[df_test['icustayid'] == uid]\n",
    "    phys_vals.append(sum(traj['reward']))\n",
    "np.mean(phys_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
